{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774c1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n",
    "# https://cookbook.openai.com/examples/using_tool_required_for_customer_service\n",
    "from spire.doc import *\n",
    "from spire.doc.common import *\n",
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import ast \n",
    "import pandas as pd\n",
    "import json\n",
    "import tiktoken\n",
    "# Create a Document instance\n",
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcfabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = dotenv_values(\"../api_data.env\")\n",
    "openai.api_key = api_key['OPEN_AI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632d5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d51925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf664b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x24c2bda1dc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ebcf7",
   "metadata": {},
   "source": [
    "# Function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5581258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"alerting_db_ver6\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93706d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: alerts_table,Columns in alerts_table:alert_id, alert_date, trader_id, model_name\n",
      "Table: deals_table,Columns in deals_table:alert_id, deal_number, price, volume\n"
     ]
    }
   ],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n",
    "\n",
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']},Columns in {table['table_name']}:{', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")\n",
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5b66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database_function(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = pd.read_sql_query(query, conn)\n",
    "        #results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad40e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>alert_id</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>deal_number</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>price</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>volume</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid         name     type  notnull dflt_value  pk\n",
       "0    0     alert_id  INTEGER        0       None   0\n",
       "1    1  deal_number     TEXT        0       None   0\n",
       "2    2        price  INTEGER        0       None   0\n",
       "3    3       volume  INTEGER        0       None   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =  \"PRAGMA table_info(deals_table);\"\n",
    "#df = pd.read_sql_query(query, conn)\n",
    "a = ask_database_function(conn,query)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382cec3",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ee593",
   "metadata": {},
   "source": [
    "### Reading the Embedding df with text and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90bf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Embedding_df/embedding_Macquarie_Group_announces_$A3.csv').drop(columns = ['Unnamed: 0'])\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1f1f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FY24 net profit of $A3,522 million, down 32% o...</td>\n",
       "      <td>[[0.026646699756383896, 0.009173554368317127, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...</td>\n",
       "      <td>[[0.010210090316832066, 0.041706670075654984, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annuity-style activities, which are undertaken...</td>\n",
       "      <td>[[0.0324883796274662, 0.04309939965605736, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assets under management at 31 March 2024 were ...</td>\n",
       "      <td>[[0.05020987242460251, 0.02893919125199318, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macquarie’s financial position exceeds the Aus...</td>\n",
       "      <td>[[0.0031701396219432354, 0.024023061618208885,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  FY24 net profit of $A3,522 million, down 32% o...   \n",
       "1  Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...   \n",
       "2  Annuity-style activities, which are undertaken...   \n",
       "3  Assets under management at 31 March 2024 were ...   \n",
       "4  Macquarie’s financial position exceeds the Aus...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[0.026646699756383896, 0.009173554368317127, ...  \n",
       "1  [[0.010210090316832066, 0.041706670075654984, ...  \n",
       "2  [[0.0324883796274662, 0.04309939965605736, 0.0...  \n",
       "3  [[0.05020987242460251, 0.02893919125199318, 0....  \n",
       "4  [[0.0031701396219432354, 0.024023061618208885,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c1554",
   "metadata": {},
   "source": [
    "### Function to fetch the closed text paras for the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0e4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "# search function\n",
    "from scipy import spatial \n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    print(\"query_embedding:\",type(query_embedding))\n",
    "    print(\"df:\",type(df['embedding'][0]))\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below articles on the SOW of a Company to answer questions\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about the macquarie annual report news.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f850052",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2abbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The tools our customer service LLM will use to communicate\n",
    "# tools = [\n",
    "# {\n",
    "#   \"type\": \"function\",\n",
    "#   \"function\": {\n",
    "#     \"name\": \"Answer_generic_questions\",\n",
    "#     \"description\": \"\"\"Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n",
    "#                       Read the whole previous conversation till the lastest user query and see if you answer.\n",
    "#                       User might ask to summarize any document, do spell check or write a mailer for him/her\"\"\",\n",
    "#     \"parameters\": {\n",
    "#       \"type\": \"object\",\n",
    "#       \"properties\": {\n",
    "#         \"message\": {\n",
    "#           \"type\": \"string\",\n",
    "#           \"description\": \"Text of message to send to user. Can cover multiple topics.\"\n",
    "#         }\n",
    "#       },\n",
    "#       \"required\": [\"message\"]\n",
    "#     }\n",
    "#   }\n",
    "# },\n",
    "# {\n",
    "#   \"type\": \"function\",\n",
    "#   \"function\": {\n",
    "#     \"name\": \"get_information\",\n",
    "#     \"description\": \"Used to get instructions to deal with the user's problem.\",\n",
    "#     \"parameters\": {\n",
    "#       \"type\": \"object\",\n",
    "#       \"properties\": {\n",
    "#         \"information\": {\n",
    "#           \"type\": \"string\",\n",
    "#           \"description\": \"\"\"The user wants to know information about the Macquarie annual report.\n",
    "#                             Use the embedding search functionality to answer properly. \"\"\"\n",
    "#         }\n",
    "#       },\n",
    "#       \"required\": [\n",
    "#         \"information\"\n",
    "#       ]\n",
    "#     }\n",
    "#   }\n",
    "# },\n",
    "# {\n",
    "#     \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#         \"name\": \"ask_database\",\n",
    "#         \"description\": \"Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"query\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": f\"\"\"\n",
    "#                             SQL query extracting info to answer the user's question.\n",
    "#                             SQL should be written using this database schema: {database_schema_string}\n",
    "#                             SQL must use alerts as alias name for alerts table and deals as alias name for deals_table.\n",
    "#                             The query should only select from the tables mentioned in {database_schema_string}\n",
    "#                             Use Table joins if you dont get right information from a single table.\n",
    "#                             SQL query for any syntax error and if there are any, correct it so that it can run easily on SQLite database.\n",
    "#                             The query should be returned in plain text, not in JSON.\n",
    "#                             \"\"\",\n",
    "#                 },\n",
    "#                 \"data_analysis\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": f\"\"\"\n",
    "#                             The data_analysis should return none if the user has asked only for the sql query.\n",
    "#                             The data_analysis should return the kind of analysis that the user as asked for.\n",
    "#                             The data_analysis should search for words like data insights,data analysis, data,insights,analysis in the user request and return what kind of analysis if asked for.\n",
    "                            \n",
    "#                             \"\"\",\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"query\",\"data_analysis\"],\n",
    "#         },\n",
    "#     }\n",
    "# }\n",
    "# ]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"Answer_generic_questions\",\n",
    "            \"description\": \"\"\"Use this to provide the user with information based on the ongoing conversation. \n",
    "                              Read the entire previous conversation up to the latest user query to formulate a comprehensive response. \n",
    "                              This can include summarizing documents, performing spell checks, or writing emails.\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"message\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The text of the message to send to the user, which can cover multiple topics.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"message\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Retrieve information to address the user's query, such as details about the Macquarie annual report.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"information\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The information the user is seeking, such as details about the Macquarie annual report. \n",
    "                                          Utilize the embedding search functionality to provide an accurate response.\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"information\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Answer user questions about Alerts and Deals in trading data using a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                        SQL query to extract information to answer the user's question. \n",
    "                                        Use the provided database schema: {database_schema_string}. \n",
    "                                        Alias 'alerts' for alerts_table and 'deals' for deals_table.\n",
    "                                        Join tables if necessary for comprehensive information.\n",
    "                                        Ensure the query is syntactically correct for SQLite database.\n",
    "                                        The query should be returned in plain text, not in JSON.\n",
    "                                       \"\"\",\n",
    "                    },\n",
    "                    \"data_analysis\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"Specify the type of data analysis requested by the user. \n",
    "                                          If no analysis is requested, return 'none'. \n",
    "                                          Identify analysis requests through keywords such as 'data insights', 'data analysis', 'data', 'insights', or 'analysis' in the user's query.\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\", \"data_analysis\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfcd9d",
   "metadata": {},
   "source": [
    "### Functions to decide with tool to pick and to generate response according to the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627996df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryRegenerate(sqlQuery, messages):\n",
    "    count = 1\n",
    "    focussed_query = sqlQuery\n",
    "    while count < 10:\n",
    "        print(\"count:\",count)\n",
    "        results = ask_database_function(conn,focussed_query)\n",
    "        if (isinstance(results,str)) & ('error' in results):\n",
    "            messages.append({\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":f\"\"\"\n",
    "                        The sql query is not incorrect and is give the error: {results}.\n",
    "                        Use the provided database schema: {database_schema_string}. \n",
    "                        Alias 'alerts' for alerts_table and 'deals' for deals_table.\n",
    "                        Join tables if necessary for comprehensive information.\n",
    "                        Ensure the query is syntactically correct for SQLite database.\n",
    "                        The query should be returned in plain text, not in JSON.\n",
    "                        \"\"\"\n",
    "                    })\n",
    "            response1 = client.chat.completions.create(model=GPT_MODEL\n",
    "                                  ,messages=messages\n",
    "                                  ,temperature=0\n",
    "                                  ,tools=tools\n",
    "                                  ,tool_choice='required'\n",
    "                                 )\n",
    "            tool_calls_refreshed = response1.choices[0].message.tool_calls\n",
    "            if tool_calls_refreshed:\n",
    "                tool_call_id = tool_calls_refreshed[0].id\n",
    "                tool_function_name = tool_calls_refreshed[0].function.name\n",
    "                tool_query_string = eval(tool_calls_refreshed[0].function.arguments)['query']\n",
    "                count+=1\n",
    "                focussed_query = tool_query_string\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    \n",
    "    return focussed_query,results\n",
    "    \n",
    "\n",
    "def execute_function(function_calls,messages):\n",
    "    \"\"\"Wrapper function to execute the tool calls\"\"\"\n",
    "    \n",
    "    #print(\"function_calls.tool_calls: \",function_calls)\n",
    "    for function_call in function_calls.tool_calls:\n",
    "    \n",
    "        function_id = function_call.id\n",
    "        function_name = function_call.function.name\n",
    "        function_arguments = json.loads(function_call.function.arguments)\n",
    "    \n",
    "        if function_name == 'get_information':\n",
    "\n",
    "            # instruction_name will have the user query:\n",
    "            instruction_name = function_arguments['information']\n",
    "            \n",
    "            \n",
    "            response_message_embedding = ask(instruction_name)\n",
    "            messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": response_message_embedding\n",
    "                        })\n",
    "            \n",
    "            print(f\"Assistant: {response_message_embedding}\")\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        elif function_name == 'ask_database':\n",
    "\n",
    "            \n",
    "            instruction_name = function_arguments['query']\n",
    "            focussed_query,results = queryRegenerate(instruction_name,messages)\n",
    "            #print(\"focussed_query:::\",focussed_query)\n",
    "            if (function_arguments['data_analysis'] != \"\") & (function_arguments['data_analysis'] != \"none\"):\n",
    "                results_dict = results.to_dict(orient='records')\n",
    "                results_json = json.dumps(results_dict)\n",
    "                #print(\" pre messages_analysis\")\n",
    "                messages.append({\n",
    "                    \"role\":\"user\", \n",
    "                    \"content\":\"provide the following analysis on the given data:\"+function_arguments['data_analysis']+\"-\"+ results_json,\n",
    "                })\n",
    "                #print(\"messages send to gpt for data analysis: \",messages)\n",
    "                response = client.chat.completions.create(\n",
    "                    model=GPT_MODEL,\n",
    "                    messages=messages,\n",
    "                    temperature=0\n",
    "                )\n",
    "                #print(\"response from gpt for data analysis:\",response)\n",
    "                response_message = response.choices[0].message.content\n",
    "                messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": \"SQL:\"+ focussed_query + \" \\n\"+response_message \n",
    "                        })\n",
    "                print(f\"Assistant: {response_message}\")\n",
    "            else:\n",
    "                messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": focussed_query\n",
    "                        })\n",
    "             \n",
    "                print(f\"Assistant: {focussed_query}\")\n",
    "                print(\"\\n\\n\")\n",
    "            \n",
    "        elif function_name == 'Answer_generic_questions':\n",
    "\n",
    "            \n",
    "            instruction_name = function_arguments['message']\n",
    "            messages.append({\n",
    "                    \"role\":\"assistant\", \n",
    "                    \"content\": instruction_name\n",
    "                    })\n",
    "\n",
    "    \n",
    "            print(f\"Assistant: {instruction_name}\")\n",
    "            print(\"\\n\\n\")\n",
    "    \n",
    "    return (messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a7f92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User: can you provide a line graph between models and price from the database.\n",
    "# PRAGMA table_info(deals_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd7091",
   "metadata": {},
   "source": [
    "### Defining the System Message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7aad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_system_prompt = \"\"\"You are a user service assistant. Your role is to answer user questions politely and competently.\n",
    "You should follow these instructions to solve the case:\n",
    "- You might be asked to provide a SQL query. Use database schema provided in tools to give back the SQl query.\n",
    "- You might be asked to provide data analysis. Provide the analysis as well we you can.\n",
    "- You might be asked about information related to Macquarie's Annual report.\n",
    "- Understand their problem and select the relevant funtions from tools.\n",
    "\n",
    "Only call a tool once in a single message.\n",
    "If you need to fetch a piece of information from a database or document that you don't have access to or you dont have the right answer, DO NOT PROVIDE answer with dummy values..\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f2237",
   "metadata": {},
   "source": [
    "### Create a simple GUI to interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "sg.theme('GreenTan') # give our window a spiffy set of colors\n",
    "\n",
    "layout = [[sg.Text('Your output will go here', size=(40, 1))],\n",
    "          [sg.Output(size=(110, 20), font=('Helvetica 10'))],\n",
    "          [sg.Multiline(size=(70, 5), enter_submits=True, key='-QUERY-', do_not_clear=False),\n",
    "           sg.Button('SEND', button_color=(sg.YELLOWS[0], sg.BLUES[0]), bind_return_key=True),\n",
    "           sg.Button('EXIT', button_color=(sg.YELLOWS[0], sg.GREENS[0]))]]\n",
    "\n",
    "window = sg.Window('Chat window', layout, font=('Helvetica', ' 13'), default_button_element_size=(8,2), use_default_focus=False)\n",
    "\n",
    "#conversation_messages = []\n",
    "messages = [\n",
    "    {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": assistant_system_prompt\n",
    "    }\n",
    "]\n",
    "try:\n",
    "    while True:     # The Event Loop\n",
    "        event, values = window.read()\n",
    "        if event in (sg.WIN_CLOSED, 'EXIT'):            # quit if exit button or X\n",
    "            break\n",
    "            #window.close()\n",
    "        if event == 'SEND':\n",
    "            #print(\"inside send\")\n",
    "            # Initiate a respond object. This will be set to True by our functions when a response is required\n",
    "       \n",
    "            user_question = values['-QUERY-'].rstrip()\n",
    "            user_message = {\"role\":\"user\",\"content\": user_question}\n",
    "            messages.append(user_message)\n",
    "\n",
    "            print(f\"User: {user_question}\")\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "            # Make the ChatCompletion call with tool_choice='required' so we can guarantee tools will be used\n",
    "            response = client.chat.completions.create(model=GPT_MODEL\n",
    "                                                      ,messages=messages\n",
    "                                                      ,temperature=0\n",
    "                                                      ,tools=tools\n",
    "                                                      ,tool_choice='required'\n",
    "                                                     )\n",
    "            \n",
    "            #print(\"Response: \",response)print(\"conversation_messages in submit_user_message: \",messages)\n",
    "            messages = execute_function(response.choices[0].message,messages)\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"Exception occured :\",e)\n",
    "    window.close()\n",
    "    \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159544aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea72813",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT data_type FROM information_schema.columns WHERE table_name = \\'deals_table\\' AND column_name = \\'price\\'\n",
    "SELECT data_type FROM information_schema.columns WHERE table_name = 'deals_table' AND column_name = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can you provide a query to get top 5 models with most alerts and provide insights into the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad10de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "can you provide the deal number having most alerts in last 2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [{\"model_name\": \"model_3\", \"alert_count\": 113}, \n",
    "        {\"model_name\": \"model_5\", \"alert_count\": 103}, \n",
    "        {\"model_name\": \"model_4\", \"alert_count\": 102}, \n",
    "        {\"model_name\": \"model_1\", \"alert_count\": 93}, \n",
    "        {\"model_name\": \"model_2\", \"alert_count\": 89}]\n",
    "\n",
    "model_names = [d['model_name'] for d in data]\n",
    "alert_counts = [d['alert_count'] for d in data]\n",
    "\n",
    "plt.bar(model_names, alert_counts)\n",
    "plt.xlabel('Model Name')\n",
    "plt.ylabel('Alert Count')\n",
    "plt.title('Alert Count per Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool call for information:\n",
    "\n",
    "tool_calls=[ChatCompletionMessageToolCall(id='call_9DckYbESC1pkmsQGTaXQOWvF', function=Function(arguments='{\"information\":\"Difference between CGM and MAM contribution in profit by number\"}', name='get_information'), type='function')])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cce39578",
   "metadata": {},
   "source": [
    "## tool call for ask databse:\n",
    "\n",
    "# tool_calls=[ChatCompletionMessageToolCall(id='call_BrcSvu8KvMirkkGJGThKRpOV', function=Function(arguments='{\"query\":\"SELECT model_name, COUNT(alert_id) AS alert_count FROM alerts_table GROUP BY model_name ORDER BY alert_count DESC LIMIT 1;\"}', name='ask_database'), type='function')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
