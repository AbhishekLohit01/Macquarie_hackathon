{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774c1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n",
    "# https://cookbook.openai.com/examples/using_tool_required_for_customer_service\n",
    "from spire.doc import *\n",
    "from spire.doc.common import *\n",
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import ast \n",
    "import pandas as pd\n",
    "import json\n",
    "import tiktoken\n",
    "# Create a Document instance\n",
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcfabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = dotenv_values(\"../api_data.env\")\n",
    "openai.api_key = api_key['OPEN_AI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632d5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d51925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ebcf7",
   "metadata": {},
   "source": [
    "# Function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5581258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"alerting_db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93706d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: alerts_table\n",
      "Columns: alert_id, alert_date, trader_id, deal_number, model_name\n",
      "Table: deals_table\n",
      "Columns: alert_id, deal_date, deal_number, price, volume\n"
     ]
    }
   ],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n",
    "\n",
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")\n",
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5b66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382cec3",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ee593",
   "metadata": {},
   "source": [
    "### Reading the Embedding df with text and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90bf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Embedding_df/embedding_Macquarie_Group_announces_$A3.csv').drop(columns = ['Unnamed: 0'])\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1f1f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FY24 net profit of $A3,522 million, down 32% o...</td>\n",
       "      <td>[[0.026646699756383896, 0.009173554368317127, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...</td>\n",
       "      <td>[[0.010210090316832066, 0.041706670075654984, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annuity-style activities, which are undertaken...</td>\n",
       "      <td>[[0.0324883796274662, 0.04309939965605736, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assets under management at 31 March 2024 were ...</td>\n",
       "      <td>[[0.05020987242460251, 0.02893919125199318, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macquarie’s financial position exceeds the Aus...</td>\n",
       "      <td>[[0.0031701396219432354, 0.024023061618208885,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  FY24 net profit of $A3,522 million, down 32% o...   \n",
       "1  Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...   \n",
       "2  Annuity-style activities, which are undertaken...   \n",
       "3  Assets under management at 31 March 2024 were ...   \n",
       "4  Macquarie’s financial position exceeds the Aus...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[0.026646699756383896, 0.009173554368317127, ...  \n",
       "1  [[0.010210090316832066, 0.041706670075654984, ...  \n",
       "2  [[0.0324883796274662, 0.04309939965605736, 0.0...  \n",
       "3  [[0.05020987242460251, 0.02893919125199318, 0....  \n",
       "4  [[0.0031701396219432354, 0.024023061618208885,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c1554",
   "metadata": {},
   "source": [
    "### Function to fetch the closed text paras for the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0e4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "# search function\n",
    "from scipy import spatial \n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below articles on the SOW of a Company to answer questions\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about the macquarie annual report news.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f850052",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f2abbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tools our customer service LLM will use to communicate\n",
    "tools = [\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"Answer_generic_questions\",\n",
    "    \"description\": \"\"\"Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n",
    "                      Read the whole previous conversation till the lastest user query and see if you answer.\n",
    "                      User might ask to summarize any document, do spell check or write a mailer for him/her\"\"\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"message\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Text of message to send to user. Can cover multiple topics.\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"message\"]\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_information\",\n",
    "    \"description\": \"Used to get instructions to deal with the user's problem.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"information\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"\"\"The user wants to know information about the Macquarie annual report.\n",
    "                            Use the embedding search functionality to answer properly. \"\"\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"information\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "# Example instructions that the customer service assistant can consult for relevant customer problems\n",
    "# INSTRUCTIONS = [ {\"type\": \"get_query\",\n",
    "#                   \"instructions\": \"\"\"• Ask the user to describe the scenerio for which they need the sql query .\n",
    "# • Offer the user the sql query.\n",
    "# • Thank the user for contacting support and invite them to reach out with any future queries.\"\"\"},\n",
    "#                 {\"type\": \"get_information\",\n",
    "#                  \"instructions\": \"\"\"• Greet the user and ask how you can assist them today.\n",
    "# • Listen carefully to the user's query and clarify if necessary.\n",
    "# • Provide accurate and clear information based on the user's questions.\n",
    "# • Offer to assist with any additional questions or provide further details if needed.\n",
    "# • Ensure the user is satisfied with the information provided.\n",
    "# • Thank the user for contacting support and invite them to reach out with any future queries.\"\"\" },\n",
    "#                {\"type\": \"ask_database\",\n",
    "#                  \"instructions\": \"\"\"• Greet the user and ask how you can assist them today.\n",
    "# • Listen carefully to the user's query and clarify if necessary.\n",
    "# • Provide accurate and clear SQL Query based on the user's questions.\n",
    "# • Offer to assist with any additional questions or provide further details if needed.\n",
    "# • Ensure the user is satisfied with the information provided.\n",
    "# • Thank the user for contacting support and invite them to reach out with any future queries.\"\"\" }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfcd9d",
   "metadata": {},
   "source": [
    "### Functions to decide with tool to pick and to generate response according to the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627996df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def submit_user_message(user_query,conversation_messages=[]):\n",
    "#     \"\"\"Message handling function which loops through tool calls until it reaches one that requires a response.\n",
    "#     Once it receives respond=True it returns the conversation_messages to the user.\"\"\"\n",
    "\n",
    "#     # Initiate a respond object. This will be set to True by our functions when a response is required\n",
    "#     respond = False\n",
    "    \n",
    "#     user_message = {\"role\":\"user\",\"content\": user_query}\n",
    "#     conversation_messages.append(user_message)\n",
    "\n",
    "#     print(f\"User: {user_query}\")\n",
    "\n",
    "#     while respond is False:\n",
    "\n",
    "#         # Build a transient messages object to add the conversation messages to\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": assistant_system_prompt\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         # Add the conversation messages to our messages call to the API\n",
    "#         [messages.append(x) for x in conversation_messages]\n",
    "\n",
    "#         # Make the ChatCompletion call with tool_choice='required' so we can guarantee tools will be used\n",
    "#         response = client.chat.completions.create(model=GPT_MODEL\n",
    "#                                                   ,messages=messages\n",
    "#                                                   ,temperature=0\n",
    "#                                                   ,tools=tools\n",
    "#                                                   ,tool_choice='required'\n",
    "#                                                  )\n",
    "\n",
    "        \n",
    "#         messages.append(response.choices[0].message)\n",
    "#         print(\"conversation_messages in submit_user_message: \",messages)\n",
    "      \n",
    "#         respond, messages = execute_function(response.choices[0].message,messages)\n",
    "    \n",
    "#     return messages1\n",
    "\n",
    "def execute_function(function_calls,messages):\n",
    "    \"\"\"Wrapper function to execute the tool calls\"\"\"\n",
    "\n",
    "    for function_call in function_calls.tool_calls:\n",
    "    \n",
    "        function_id = function_call.id\n",
    "        function_name = function_call.function.name\n",
    "        function_arguments = json.loads(function_call.function.arguments)\n",
    "    \n",
    "        if function_name == 'get_information':\n",
    "\n",
    "            respond = True\n",
    "            \n",
    "            \n",
    "            # instruction_name will have the user query:\n",
    "            instruction_name = function_arguments['information']\n",
    "            \n",
    "            \n",
    "            response_message_embedding = ask(instruction_name)\n",
    "            messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": response_message_embedding\n",
    "                        })\n",
    "            \n",
    "            print(f\"Assistant: {response_message_embedding}\")\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        elif function_name == 'ask_database':\n",
    "\n",
    "            respond = True\n",
    "    \n",
    "            instruction_name = function_arguments['query']\n",
    "            messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": instruction_name\n",
    "                        })\n",
    "             \n",
    "            print(f\"Assistant: {instruction_name}\")\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        elif function_name == 'Answer_generic_questions':\n",
    "\n",
    "            respond = True\n",
    "            instruction_name = function_arguments['message']\n",
    "            messages.append({\n",
    "                    \"role\":\"assistant\", \n",
    "                    \"content\": instruction_name\n",
    "                    })\n",
    "\n",
    "    \n",
    "            print(f\"Assistant: {instruction_name}\")\n",
    "            print(\"\\n\\n\")\n",
    "    \n",
    "    return (respond, messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd7091",
   "metadata": {},
   "source": [
    "### Defining the System Message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7aad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_system_prompt = \"\"\"You are a user service assistant. Your role is to answer user questions politely and competently.\n",
    "You should follow these instructions to solve the case:\n",
    "- Understand their problem and get the relevant instructions.\n",
    "- Follow the instructions to solve the user's problem.\n",
    "- Help them with any other problems or close the case.\n",
    "\n",
    "Only call a tool once in a single message.\n",
    "If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f2237",
   "metadata": {},
   "source": [
    "### Create a simple GUI to interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd9b4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "sg.theme('GreenTan') # give our window a spiffy set of colors\n",
    "\n",
    "layout = [[sg.Text('Your output will go here', size=(40, 1))],\n",
    "          [sg.Output(size=(110, 20), font=('Helvetica 10'))],\n",
    "          [sg.Multiline(size=(70, 5), enter_submits=True, key='-QUERY-', do_not_clear=False),\n",
    "           sg.Button('SEND', button_color=(sg.YELLOWS[0], sg.BLUES[0]), bind_return_key=True),\n",
    "           sg.Button('EXIT', button_color=(sg.YELLOWS[0], sg.GREENS[0]))]]\n",
    "\n",
    "window = sg.Window('Chat window', layout, font=('Helvetica', ' 13'), default_button_element_size=(8,2), use_default_focus=False)\n",
    "\n",
    "#conversation_messages = []\n",
    "messages = [\n",
    "    {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": assistant_system_prompt\n",
    "    }\n",
    "]\n",
    "try:\n",
    "    while True:     # The Event Loop\n",
    "        event, values = window.read()\n",
    "        if event in (sg.WIN_CLOSED, 'EXIT'):            # quit if exit button or X\n",
    "            break\n",
    "            #window.close()\n",
    "        if event == 'SEND':\n",
    "            #print(\"inside send\")\n",
    "            # Initiate a respond object. This will be set to True by our functions when a response is required\n",
    "            respond = False\n",
    "            \n",
    "            user_question = values['-QUERY-'].rstrip()\n",
    "            user_message = {\"role\":\"user\",\"content\": user_question}\n",
    "            messages.append(user_message)\n",
    "\n",
    "            print(f\"User: {user_question}\")\n",
    "            #print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "            # Make the ChatCompletion call with tool_choice='required' so we can guarantee tools will be used\n",
    "            response = client.chat.completions.create(model=GPT_MODEL\n",
    "                                                      ,messages=messages\n",
    "                                                      ,temperature=0\n",
    "                                                      ,tools=tools\n",
    "                                                      ,tool_choice='required'\n",
    "                                                     )\n",
    "            \n",
    "            print(\"Response: \",response)\n",
    "            #print(\"conversation_messages in submit_user_message: \",messages)\n",
    "            respond, messages = execute_function(response.choices[0].message,messages)\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"Exception occured :\",e)\n",
    "    window.close()\n",
    "    \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "159544aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a user service assistant. Your role is to answer user questions politely and competently.\\nYou should follow these instructions to solve the case:\\n- Understand their problem and get the relevant instructions.\\n- Follow the instructions to solve the user's problem.\\n- Help them with any other problems or close the case.\\n\\nOnly call a tool once in a single message.\\nIf you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values.\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1785a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2af795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9cf6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool call for information:\n",
    "\n",
    "# tool_calls=[ChatCompletionMessageToolCall(id='call_9DckYbESC1pkmsQGTaXQOWvF', function=Function(arguments='{\"information\":\"Difference between CGM and MAM contribution in profit by number\"}', name='get_information'), type='function')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5dd110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tool call for ask databse:\n",
    "\n",
    "# tool_calls=[ChatCompletionMessageToolCall(id='call_BrcSvu8KvMirkkGJGThKRpOV', function=Function(arguments='{\"query\":\"SELECT model_name, COUNT(alert_id) AS alert_count FROM alerts_table GROUP BY model_name ORDER BY alert_count DESC LIMIT 1;\"}', name='ask_database'), type='function')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
