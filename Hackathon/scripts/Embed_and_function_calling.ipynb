{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fe276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from spire.doc import *\n",
    "from spire.doc.common import *\n",
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import ast \n",
    "import pandas as pd\n",
    "import json\n",
    "import tiktoken\n",
    "# Create a Document instance\n",
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd04f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = dotenv_values(\"../api_data.env\")\n",
    "openai.api_key = api_key['OPEN_AI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97ad157",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6622fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba50fdb",
   "metadata": {},
   "source": [
    "### Function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997e664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"alerting_db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59731140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: alerts_table\n",
      "Columns: alert_id, alert_date, trader_id, deal_number, model_name\n",
      "Table: deals_table\n",
      "Columns: alert_id, deal_date, deal_number, price, volume\n"
     ]
    }
   ],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n",
    "\n",
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")\n",
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03eb3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824214c4",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a47b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Embedding_df/embedding_Macquarie_Group_announces_$A3.csv').drop(columns = ['Unnamed: 0'])\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2e3dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FY24 net profit of $A3,522 million, down 32% o...</td>\n",
       "      <td>[[0.026646699756383896, 0.009173554368317127, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...</td>\n",
       "      <td>[[0.010210090316832066, 0.041706670075654984, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annuity-style activities, which are undertaken...</td>\n",
       "      <td>[[0.0324883796274662, 0.04309939965605736, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assets under management at 31 March 2024 were ...</td>\n",
       "      <td>[[0.05020987242460251, 0.02893919125199318, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macquarie’s financial position exceeds the Aus...</td>\n",
       "      <td>[[0.0031701396219432354, 0.024023061618208885,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  FY24 net profit of $A3,522 million, down 32% o...   \n",
       "1  Bank Level 2 CET1 ratio 13.6% (Harmonised5: 18...   \n",
       "2  Annuity-style activities, which are undertaken...   \n",
       "3  Assets under management at 31 March 2024 were ...   \n",
       "4  Macquarie’s financial position exceeds the Aus...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[0.026646699756383896, 0.009173554368317127, ...  \n",
       "1  [[0.010210090316832066, 0.041706670075654984, ...  \n",
       "2  [[0.0324883796274662, 0.04309939965605736, 0.0...  \n",
       "3  [[0.05020987242460251, 0.02893919125199318, 0....  \n",
       "4  [[0.0031701396219432354, 0.024023061618208885,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bd3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "# search function\n",
    "from scipy import spatial \n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below articles on the SOW of a Company to answer questions\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about the macquarie annual report news.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10539d6",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393a26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tools our customer service LLM will use to communicate\n",
    "tools = [\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"Answer_generic_questions\",\n",
    "    \"description\": \"\"\"Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n",
    "                      Read the whole previous conversation till the lastest user query and see if you answer.\n",
    "                      User might ask to summarize any document, do spell check or write a mailer for him/her\"\"\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"message\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Text of message to send to user. Can cover multiple topics.\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"message\"]\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_information\",\n",
    "    \"description\": \"Used to get instructions to deal with the user's problem.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"information\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"\"\"The user wants to know information about the Macquarie annual report.\n",
    "                            Use the embedding search functionality to answer properly. \"\"\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"information\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "# Example instructions that the customer service assistant can consult for relevant customer problems\n",
    "INSTRUCTIONS = [ {\"type\": \"get_query\",\n",
    "                  \"instructions\": \"\"\"• Ask the user to describe the scenerio for which they need the sql query .\n",
    "• Offer the user the sql query.\n",
    "• Thank the user for contacting support and invite them to reach out with any future queries.\"\"\"},\n",
    "                {\"type\": \"get_information\",\n",
    "                 \"instructions\": \"\"\"• Greet the user and ask how you can assist them today.\n",
    "• Listen carefully to the user's query and clarify if necessary.\n",
    "• Provide accurate and clear information based on the user's questions.\n",
    "• Offer to assist with any additional questions or provide further details if needed.\n",
    "• Ensure the user is satisfied with the information provided.\n",
    "• Thank the user for contacting support and invite them to reach out with any future queries.\"\"\" },\n",
    "               {\"type\": \"ask_database\",\n",
    "                 \"instructions\": \"\"\"• Greet the user and ask how you can assist them today.\n",
    "• Listen carefully to the user's query and clarify if necessary.\n",
    "• Provide accurate and clear SQL Query based on the user's questions.\n",
    "• Offer to assist with any additional questions or provide further details if needed.\n",
    "• Ensure the user is satisfied with the information provided.\n",
    "• Thank the user for contacting support and invite them to reach out with any future queries.\"\"\" }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12200e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_system_prompt = \"\"\"You are a user service assistant. Your role is to answer user questions politely and competently.\n",
    "You should follow these instructions to solve the case:\n",
    "- Understand their problem and get the relevant instructions.\n",
    "- Follow the instructions to solve the user's problem.\n",
    "- Help them with any other problems or close the case.\n",
    "\n",
    "Only call a tool once in a single message.\n",
    "If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values.\"\"\"\n",
    "\n",
    "def submit_user_message(user_query,conversation_messages=[]):\n",
    "    \"\"\"Message handling function which loops through tool calls until it reaches one that requires a response.\n",
    "    Once it receives respond=True it returns the conversation_messages to the user.\"\"\"\n",
    "\n",
    "    # Initiate a respond object. This will be set to True by our functions when a response is required\n",
    "    respond = False\n",
    "    \n",
    "    user_message = {\"role\":\"user\",\"content\": user_query}\n",
    "    conversation_messages.append(user_message)\n",
    "\n",
    "    print(f\"User: {user_query}\")\n",
    "\n",
    "    while respond is False:\n",
    "\n",
    "        # Build a transient messages object to add the conversation messages to\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": assistant_system_prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Add the conversation messages to our messages call to the API\n",
    "        [messages.append(x) for x in conversation_messages]\n",
    "\n",
    "        # Make the ChatCompletion call with tool_choice='required' so we can guarantee tools will be used\n",
    "        response = client.chat.completions.create(model=GPT_MODEL\n",
    "                                                  ,messages=messages\n",
    "                                                  ,temperature=0\n",
    "                                                  ,tools=tools\n",
    "                                                  ,tool_choice='required'\n",
    "                                                 )\n",
    "\n",
    "        \n",
    "        messages.append(response.choices[0].message)\n",
    "        print(\"conversation_messages in submit_user_message: \",messages)\n",
    "        #respond = True\n",
    "        # Execute the function and get an updated conversation_messages object back\n",
    "        # If it doesn't require a response, it will ask the assistant again. \n",
    "        # If not the results are returned to the user.\n",
    "        respond, messages = execute_function(response.choices[0].message,messages)\n",
    "    \n",
    "    return messages1\n",
    "\n",
    "def execute_function(function_calls,messages):\n",
    "    \"\"\"Wrapper function to execute the tool calls\"\"\"\n",
    "\n",
    "    for function_call in function_calls.tool_calls:\n",
    "    \n",
    "        function_id = function_call.id\n",
    "        function_name = function_call.function.name\n",
    "        #print(f\"Calling function {function_name}\")\n",
    "        function_arguments = json.loads(function_call.function.arguments)\n",
    "    \n",
    "        if function_name == 'get_information':\n",
    "\n",
    "            respond = True\n",
    "            #print(\"Inside get_information\")\n",
    "            \n",
    "            # instruction_name will have the user query:\n",
    "            instruction_name = function_arguments['information']\n",
    "            #instructions = INSTRUCTIONS['type' == instruction_name]\n",
    "            \n",
    "            response_message_embedding = ask(instruction_name)\n",
    "            messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": response_message_embedding\n",
    "                        })\n",
    "#             messages.append(\n",
    "#                                 {\n",
    "#                                     \"tool_call_id\": function_id,\n",
    "#                                     \"role\": \"tool\",\n",
    "#                                     \"name\": function_name,\n",
    "#                                     \"content\": response_message_embedding,\n",
    "#                                 }\n",
    "#                             )\n",
    "            print(f\"Assistant: {response_message_embedding}\")\n",
    "            #print(response_message_embedding)\n",
    "        elif function_name == 'ask_database':\n",
    "\n",
    "            respond = True\n",
    "    \n",
    "            instruction_name = function_arguments['query']\n",
    "            messages.append({\n",
    "                        \"role\":\"assistant\", \n",
    "                        \"content\": instruction_name\n",
    "                        })\n",
    "#             instructions = INSTRUCTIONS['type' == instruction_name]\n",
    "#             messages.append(\n",
    "#                                 {\n",
    "#                                     \"tool_call_id\": function_id,\n",
    "#                                     \"role\": \"tool\",\n",
    "#                                     \"name\": function_name,\n",
    "#                                     \"content\": instruction_name,\n",
    "                                    \n",
    "#                                 }\n",
    "#                             )\n",
    "            print(f\"Assistant: {instruction_name}\")\n",
    "            #print(instruction_name)\n",
    "        elif function_name == 'Answer_generic_questions':\n",
    "\n",
    "            respond = True\n",
    "            instruction_name = function_arguments['message']\n",
    "            messages.append({\n",
    "                    \"role\":\"assistant\", \n",
    "                    \"content\": instruction_name\n",
    "                    })\n",
    "\n",
    "    \n",
    "            print(f\"Assistant: {instruction_name}\")\n",
    "    \n",
    "    return (respond, messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fd78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_messages = []\n",
    "# conv_messages.append(submit_user_message(\"Difference between CGM and MAM contribution in profit by number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbe5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_messages.append(submit_user_message(\"return me a query for model with most alerts\"))\n",
    "# #messages = submit_user_message(\"return me a query for model with most alerts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b742b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_system_prompt = \"\"\"You are a user service assistant. Your role is to answer user questions politely and competently.\n",
    "You should follow these instructions to solve the case:\n",
    "- Understand their problem and get the relevant instructions.\n",
    "- Follow the instructions to solve the user's problem.\n",
    "- Help them with any other problems or close the case.\n",
    "\n",
    "Only call a tool once in a single message.\n",
    "If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "116152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "'''\n",
    "A simple send/response chat window.  Add call to your send-routine and print the response\n",
    "If async responses can come in, then will need to use a different design that uses PySimpleGUI async design pattern\n",
    "\n",
    "Copyright 2023 PySimpleSoft, Inc. and/or its licensors. All rights reserved.\n",
    "\n",
    "Redistribution, modification, or any other use of PySimpleGUI or any portion thereof is subject to the terms of the PySimpleGUI License Agreement available at https://eula.pysimplegui.com.\n",
    "\n",
    "You may not redistribute, modify or otherwise use PySimpleGUI or its contents except pursuant to the PySimpleGUI License Agreement.\n",
    "\n",
    "'''\n",
    "\n",
    "sg.theme('GreenTan') # give our window a spiffy set of colors\n",
    "\n",
    "layout = [[sg.Text('Your output will go here', size=(40, 1))],\n",
    "          [sg.Output(size=(110, 20), font=('Helvetica 10'))],\n",
    "          [sg.Multiline(size=(70, 5), enter_submits=True, key='-QUERY-', do_not_clear=False),\n",
    "           sg.Button('SEND', button_color=(sg.YELLOWS[0], sg.BLUES[0]), bind_return_key=True),\n",
    "           sg.Button('EXIT', button_color=(sg.YELLOWS[0], sg.GREENS[0]))]]\n",
    "\n",
    "window = sg.Window('Chat window', layout, font=('Helvetica', ' 13'), default_button_element_size=(8,2), use_default_focus=False)\n",
    "\n",
    "#conversation_messages = []\n",
    "messages = [\n",
    "    {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": assistant_system_prompt\n",
    "    }\n",
    "]\n",
    "try:\n",
    "    while True:     # The Event Loop\n",
    "        event, values = window.read()\n",
    "        if event in (sg.WIN_CLOSED, 'EXIT'):            # quit if exit button or X\n",
    "            break\n",
    "            #window.close()\n",
    "        if event == 'SEND':\n",
    "            #print(\"inside send\")\n",
    "            # Initiate a respond object. This will be set to True by our functions when a response is required\n",
    "            respond = False\n",
    "            \n",
    "            user_question = values['-QUERY-'].rstrip()\n",
    "            user_message = {\"role\":\"user\",\"content\": user_question}\n",
    "            messages.append(user_message)\n",
    "\n",
    "            print(f\"User: {user_question}\")\n",
    "\n",
    "            \n",
    "            # Make the ChatCompletion call with tool_choice='required' so we can guarantee tools will be used\n",
    "            response = client.chat.completions.create(model=GPT_MODEL\n",
    "                                                      ,messages=messages\n",
    "                                                      ,temperature=0\n",
    "                                                      ,tools=tools\n",
    "                                                      ,tool_choice='required'\n",
    "                                                     )\n",
    "\n",
    "            #messages.append(response.choices[0].message)\n",
    "            #print(\"conversation_messages in submit_user_message: \",messages)\n",
    "            respond, messages = execute_function(response.choices[0].message,messages)\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"Exception occured :\",e)\n",
    "    window.close()\n",
    "    \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4c6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd73e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659547c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562d880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c915670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66f6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool call for information:\n",
    "\n",
    "# tool_calls=[ChatCompletionMessageToolCall(id='call_9DckYbESC1pkmsQGTaXQOWvF', function=Function(arguments='{\"information\":\"Difference between CGM and MAM contribution in profit by number\"}', name='get_information'), type='function')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tool call for ask databse:\n",
    "\n",
    "# tool_calls=[ChatCompletionMessageToolCall(id='call_BrcSvu8KvMirkkGJGThKRpOV', function=Function(arguments='{\"query\":\"SELECT model_name, COUNT(alert_id) AS alert_count FROM alerts_table GROUP BY model_name ORDER BY alert_count DESC LIMIT 1;\"}', name='ask_database'), type='function')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
