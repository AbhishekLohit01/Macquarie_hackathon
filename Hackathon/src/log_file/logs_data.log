DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a user service assistant. Your role is to answer user questions politely and competently.\n        You should follow these instructions to solve the case:\n        - Understand their problem and get the relevant instructions.\n        - Follow the instructions to solve the user's problem.\n        - Help them with any other problems or close the case.\n\n        Only call a tool once in a single message.\n        If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values."}, {'role': 'user', 'content': 'macquarie profit in numbers in 2024?'}], 'model': 'gpt-3.5-turbo', 'temperature': 0, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'Answer_generic_questions', 'description': 'Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n                                Read the whole previous conversation till the lastest user query and see if you answer.\n                                User might ask to summarize any document, do spell check or write a mailer for him/her', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Text of message to send to user. Can cover multiple topics.'}}, 'required': ['message']}}}, {'type': 'function', 'function': {'name': 'get_information', 'description': "Used to get instructions to deal with the user's problem.", 'parameters': {'type': 'object', 'properties': {'information': {'type': 'string', 'description': 'The user wants to know information about the Macquarie annual report.\n                                        Use the embedding search functionality to answer properly. '}}, 'required': ['information']}}}, {'type': 'function', 'function': {'name': 'ask_database', 'description': 'Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "\n                                        SQL query extracting info to answer the user's question.\n                                        SQL should be written using this database schema:\n                                        <bound method function_calling.database_schema_string of <__main__.chat object at 0x000002718D75D040>>\n                                        The query should be returned in plain text, not in JSON.\n                                        "}}, 'required': ['query']}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002718D91E520>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002718C48DB40> server_hostname='api.openai.com' timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002718D91E370>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:37:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'490'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59829'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'171ms'), (b'x-request-id', b'req_d5e9c0b9fae3bf0e8bdd5224f091767f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jC_.paYMeHtqdos3NFgDzJIRx_J1MG8kcZ_XnikVbSc-1720784223-1.0.1.1-fZTLseY7JGEjq6YVevJRsFBeF78W3SrW8xuzIWDubGVdudqTyIPXzLyLpogMUir2xbCc0XJN3u.Z4IYHGZB3yA; path=/; expires=Fri, 12-Jul-24 12:07:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=JrUhfZbGnBjY71iw8lZS6qRMrDkcuYy.AZQETD9Xi64-1720784223069-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20bd2c6dc97f7a-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Jul 2024 11:37:03 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'user-wklbgyuzbqmtrhk8lyys0eg5'), ('openai-processing-ms', '490'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '60000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '59829'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '171ms'), ('x-request-id', 'req_d5e9c0b9fae3bf0e8bdd5224f091767f'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=jC_.paYMeHtqdos3NFgDzJIRx_J1MG8kcZ_XnikVbSc-1720784223-1.0.1.1-fZTLseY7JGEjq6YVevJRsFBeF78W3SrW8xuzIWDubGVdudqTyIPXzLyLpogMUir2xbCc0XJN3u.Z4IYHGZB3yA; path=/; expires=Fri, 12-Jul-24 12:07:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('set-cookie', '_cfuvid=JrUhfZbGnBjY71iw8lZS6qRMrDkcuYy.AZQETD9Xi64-1720784223069-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8a20bd2c6dc97f7a-MAA'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
DEBUG:openai._base_client:request_id: req_d5e9c0b9fae3bf0e8bdd5224f091767f
INFO:root:inside execute_function
INFO:root:inside get_information
INFO:root:Inside ask function
INFO:root:Inside query_message function
INFO:root:pre embedding call
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000002718D9CCE50>, 'json_data': {'input': 'Macquarie profit in 2024', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:37:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'17'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999993'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_0586e28207143177d8910ae44a50e356'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20bd328e867f7a-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Fri, 12 Jul 2024 11:37:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-wklbgyuzbqmtrhk8lyys0eg5', 'openai-processing-ms': '17', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999993', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_0586e28207143177d8910ae44a50e356', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a20bd328e867f7a-MAA', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_0586e28207143177d8910ae44a50e356
INFO:root:post embedding call
INFO:root:post1 embedding call
INFO:root:message+q: Use the below articles on the SOW of a Company to answer questions"

Wikipedia article section:
"""
Annuity-style activities, which are undertaken by Macquarie Asset Management (MAM), Banking and Financial Services (BFS) and certain businesses in Commodities and Global Markets (CGM), generated a combined net profit contribution7 of $A3,014 million, down 27 per cent on FY23, which was primarily due to lower asset realisations in green investments and continued investment in the development of green energy portfolio companies in MAM. Markets-facing activities, which are undertaken by Macquarie Capital and most businesses in CGM, delivered a combined net profit contribution of $A3,699 million, down 40 per cent on FY23, which was notably characterised by exceptional levels of volatility in commodity markets that drove a record FY23 performance from CGM. Net operating income of $A16,887 million was down 12 per cent on FY23, while operating expenses of $A12,061 million were broadly in line with FY23. International income accounted for 66 per cent of Macquarie’s total income. The income tax expense of $A1,291 million was down 29 per cent on FY23 and the effective tax rate was 26.8 per cent8, up from 26.0 per cent in FY23. The higher effective tax rate was mainly driven by the geographic composition and nature of earnings. At 31 March 2024, the Group employed 20,666 people9, which was up one per cent on 31 March 2023. In addition, approximately 236,000 people were employed across managed fund assets and investments10.
"""

Question: Macquarie profit in 2024
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You answer questions about the macquarie annual report news.'}, {'role': 'user', 'content': 'Use the below articles on the SOW of a Company to answer questions"\n\nWikipedia article section:\n"""\nAnnuity-style activities, which are undertaken by Macquarie Asset Management (MAM), Banking and Financial Services (BFS) and certain businesses in Commodities and Global Markets (CGM), generated a combined net profit contribution7 of $A3,014 million, down 27 per cent on FY23, which was primarily due to lower asset realisations in green investments and continued investment in the development of green energy portfolio companies in MAM. Markets-facing activities, which are undertaken by Macquarie Capital and most businesses in CGM, delivered a combined net profit contribution of $A3,699 million, down 40 per cent on FY23, which was notably characterised by exceptional levels of volatility in commodity markets that drove a record FY23 performance from CGM. Net operating income of $A16,887 million was down 12 per cent on FY23, while operating expenses of $A12,061 million were broadly in line with FY23. International income accounted for 66 per cent of Macquarie’s total income. The income tax expense of $A1,291 million was down 29 per cent on FY23 and the effective tax rate was 26.8 per cent8, up from 26.0 per cent in FY23. The higher effective tax rate was mainly driven by the geographic composition and nature of earnings. At 31 March 2024, the Group employed 20,666 people9, which was up one per cent on 31 March 2023. In addition, approximately 236,000 people were employed across managed fund assets and investments10.\n"""\n\nQuestion: Macquarie profit in 2024'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 50, 'temperature': 0}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:37:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'593'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59538'), (b'x-ratelimit-reset-requests', b'15.569s'), (b'x-ratelimit-reset-tokens', b'462ms'), (b'x-request-id', b'req_0334ec19121722af537572be3f91dff9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20bd373cd87f7a-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Jul 2024 11:37:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-wklbgyuzbqmtrhk8lyys0eg5', 'openai-processing-ms': '593', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '60000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '59538', 'x-ratelimit-reset-requests': '15.569s', 'x-ratelimit-reset-tokens': '462ms', 'x-request-id': 'req_0334ec19121722af537572be3f91dff9', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a20bd373cd87f7a-MAA', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_0334ec19121722af537572be3f91dff9
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a user service assistant. Your role is to answer user questions politely and competently.\n        You should follow these instructions to solve the case:\n        - Understand their problem and get the relevant instructions.\n        - Follow the instructions to solve the user's problem.\n        - Help them with any other problems or close the case.\n\n        Only call a tool once in a single message.\n        If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values."}, {'role': 'user', 'content': 'macquarie profit in numbers in 2024?'}, {'role': 'assistant', 'content': 'Macquarie reported a combined net profit contribution of $A6,713 million in 2024.'}, {'role': 'user', 'content': 'query for most alerts by a model'}], 'model': 'gpt-3.5-turbo', 'temperature': 0, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'Answer_generic_questions', 'description': 'Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n                                Read the whole previous conversation till the lastest user query and see if you answer.\n                                User might ask to summarize any document, do spell check or write a mailer for him/her', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Text of message to send to user. Can cover multiple topics.'}}, 'required': ['message']}}}, {'type': 'function', 'function': {'name': 'get_information', 'description': "Used to get instructions to deal with the user's problem.", 'parameters': {'type': 'object', 'properties': {'information': {'type': 'string', 'description': 'The user wants to know information about the Macquarie annual report.\n                                        Use the embedding search functionality to answer properly. '}}, 'required': ['information']}}}, {'type': 'function', 'function': {'name': 'ask_database', 'description': 'Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "\n                                        SQL query extracting info to answer the user's question.\n                                        SQL should be written using this database schema:\n                                        <bound method function_calling.database_schema_string of <__main__.chat object at 0x000002718D75D040>>\n                                        The query should be returned in plain text, not in JSON.\n                                        "}}, 'required': ['query']}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002719101CA30>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002718C48DB40> server_hostname='api.openai.com' timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002719101CFA0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:37:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'713'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59799'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'201ms'), (b'x-request-id', b'req_baa1078b621a930c30b7925a098660e4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20bd9a4bfe7ec4-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Jul 2024 11:37:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-wklbgyuzbqmtrhk8lyys0eg5', 'openai-processing-ms': '713', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '60000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '59799', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '201ms', 'x-request-id': 'req_baa1078b621a930c30b7925a098660e4', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a20bd9a4bfe7ec4-MAA', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_baa1078b621a930c30b7925a098660e4
INFO:root:inside execute_function
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a user service assistant. Your role is to answer user questions politely and competently.\n        You should follow these instructions to solve the case:\n        - Understand their problem and get the relevant instructions.\n        - Follow the instructions to solve the user's problem.\n        - Help them with any other problems or close the case.\n\n        Only call a tool once in a single message.\n        If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values."}, {'role': 'user', 'content': 'macquarie profit in numbers in 2024?'}, {'role': 'assistant', 'content': 'Macquarie reported a combined net profit contribution of $A6,713 million in 2024.'}, {'role': 'user', 'content': 'query for most alerts by a model'}, {'role': 'assistant', 'content': 'SELECT model, COUNT(alert_id) AS num_alerts FROM Alerts GROUP BY model ORDER BY num_alerts DESC LIMIT 1;'}, {'role': 'user', 'content': 'can you draft a mail for me to jason and add the this chat conversation as subject?'}], 'model': 'gpt-3.5-turbo', 'temperature': 0, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'Answer_generic_questions', 'description': 'Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n                                Read the whole previous conversation till the lastest user query and see if you answer.\n                                User might ask to summarize any document, do spell check or write a mailer for him/her', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Text of message to send to user. Can cover multiple topics.'}}, 'required': ['message']}}}, {'type': 'function', 'function': {'name': 'get_information', 'description': "Used to get instructions to deal with the user's problem.", 'parameters': {'type': 'object', 'properties': {'information': {'type': 'string', 'description': 'The user wants to know information about the Macquarie annual report.\n                                        Use the embedding search functionality to answer properly. '}}, 'required': ['information']}}}, {'type': 'function', 'function': {'name': 'ask_database', 'description': 'Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "\n                                        SQL query extracting info to answer the user's question.\n                                        SQL should be written using this database schema:\n                                        <bound method function_calling.database_schema_string of <__main__.chat object at 0x000002718D75D040>>\n                                        The query should be returned in plain text, not in JSON.\n                                        "}}, 'required': ['query']}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000271910147C0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002718C48DB40> server_hostname='api.openai.com' timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027191014250>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:38:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'1042'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59750'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'250ms'), (b'x-request-id', b'req_6c42516c8e6899c4cb8baa7034e8fcf1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20beb2388e7eb5-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Jul 2024 11:38:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-wklbgyuzbqmtrhk8lyys0eg5', 'openai-processing-ms': '1042', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '60000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '59750', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '250ms', 'x-request-id': 'req_6c42516c8e6899c4cb8baa7034e8fcf1', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a20beb2388e7eb5-MAA', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_6c42516c8e6899c4cb8baa7034e8fcf1
INFO:root:inside execute_function
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a user service assistant. Your role is to answer user questions politely and competently.\n        You should follow these instructions to solve the case:\n        - Understand their problem and get the relevant instructions.\n        - Follow the instructions to solve the user's problem.\n        - Help them with any other problems or close the case.\n\n        Only call a tool once in a single message.\n        If you need to fetch a piece of information from a system or document that you don't have access to, give a clear, confident answer with some dummy values."}, {'role': 'user', 'content': 'macquarie profit in numbers in 2024?'}, {'role': 'assistant', 'content': 'Macquarie reported a combined net profit contribution of $A6,713 million in 2024.'}, {'role': 'user', 'content': 'query for most alerts by a model'}, {'role': 'assistant', 'content': 'SELECT model, COUNT(alert_id) AS num_alerts FROM Alerts GROUP BY model ORDER BY num_alerts DESC LIMIT 1;'}, {'role': 'user', 'content': 'can you draft a mail for me to jason and add the this chat conversation as subject?'}, {'role': 'assistant', 'content': 'Sure, I can help you draft the email. Could you please provide me with the content you would like to include in the email to Jason?'}, {'role': 'user', 'content': 'can you please add the query that you returned as mail body'}], 'model': 'gpt-3.5-turbo', 'temperature': 0, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'Answer_generic_questions', 'description': 'Use this to speak to the user to give them information using the ongoing conversation and a apt response.\n                                Read the whole previous conversation till the lastest user query and see if you answer.\n                                User might ask to summarize any document, do spell check or write a mailer for him/her', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Text of message to send to user. Can cover multiple topics.'}}, 'required': ['message']}}}, {'type': 'function', 'function': {'name': 'get_information', 'description': "Used to get instructions to deal with the user's problem.", 'parameters': {'type': 'object', 'properties': {'information': {'type': 'string', 'description': 'The user wants to know information about the Macquarie annual report.\n                                        Use the embedding search functionality to answer properly. '}}, 'required': ['information']}}}, {'type': 'function', 'function': {'name': 'ask_database', 'description': 'Use this function to answer user questions about Alerts and Deals in trading data. Input should be a fully formed SQL query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "\n                                        SQL query extracting info to answer the user's question.\n                                        SQL should be written using this database schema:\n                                        <bound method function_calling.database_schema_string of <__main__.chat object at 0x000002718D75D040>>\n                                        The query should be returned in plain text, not in JSON.\n                                        "}}, 'required': ['query']}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000271915DF1F0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002718C48DB40> server_hostname='api.openai.com' timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000271915DF760>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 11:38:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-wklbgyuzbqmtrhk8lyys0eg5'), (b'openai-processing-ms', b'1985'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59701'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'299ms'), (b'x-request-id', b'req_8cdabb6fcaeca50b1dbed34003444451'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a20bf5b899e7e91-MAA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Jul 2024 11:38:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-wklbgyuzbqmtrhk8lyys0eg5', 'openai-processing-ms': '1985', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '60000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '59701', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '299ms', 'x-request-id': 'req_8cdabb6fcaeca50b1dbed34003444451', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a20bf5b899e7e91-MAA', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_8cdabb6fcaeca50b1dbed34003444451
INFO:root:inside execute_function
